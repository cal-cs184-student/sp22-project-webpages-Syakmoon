<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Zhuowen Chen, Tian Liu, CS184-Spring 2022</h2>

<br><br>

<div>

<h2 align="middle">Part 1: Rasterizing single-color triangles</h2>

<p>We will start with the unoptimized naive implementation.</p>
<p>Because computers save data in a pixel world, which is typically made of rows and columns, it is the most convenient for us to determine what the shape and size and location of the triangle we are attempting to rasterize is. We will start from the lowest pixel in the x-axis and the y-axis, to the highest, by determining the boundary with <b>min(x0, x1, x2)</b>, <b>max(y0, y1, y2)</b> etc.</p>
<p>Also, because I want the center of the pixel instead of the bottom left, we will floor the point, and add 0.5 to it. Every iteration, we will move the pixel by one. In this process, we will determine whether the point we are rasterizing is in the triangle by using the line test formula in the class.</p>
<p>Because the class slide’s version assumes vertices are in clockwise direction, in our implementation, we want three line tests’ result to be greater than or equal to 0 <b>OR</b> less than or equal to 0 at the same time, in case vertices are in counterclockwise direction.</p>

<p>If the point is in the triangle, rasterize this point with the given color.</p>
<p>This is exactly equal to “one that checks each sample within the bounding box of the triangle”, because this is the way our naive implementation does.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task1-1.png" align="middle" width="1000px"/>
        <figcaption align="middle">Basic Test 4</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>In terms of the optimizations that we made, at first we tried to rearrange the for loops so that we will first go through the x-axis and then next y-axis. This is in order to achieve better cache temporal locality. And then, in looping the row, as long as it ever gets into the triangle and then gets out, there is no more need to continue in this row, so we break. This achieved in general ¾ time spent in one draw call. The C++ high resolution clock shows that the naive solution solves in 0.004s for basic test 5, but 0.003s spent for this optimization.</p>
<p>Another optimization we tried is to use the vertices with median x coordinate, draw a vertical line and find the intersection with the line between the remaining two vertices, getting the base length. Then respectively multiply it by <b>abs(median x - two other x coordinates)</b>, getting the area (no need to divide it by 2 for performance purpose). We start from the left side if the left triangle’s area is smaller, or the right side if the right triangle is smaller. This can avoid the situation when, for example, a right triangle whose right vertex is on the right boundary, so that our first optimization may not work at all. This achieved a slightly better performance, from 0.003s improved to 0.0028s.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task1-2.png" align="middle" width="1000px"/>
        <figcaption align="middle">Time Comparison Table</figcaption>
      </td>
    </tr>
  </table>
</div>
<h2 align="middle">Part 2: Antialiasing triangles</h2>


<p>Supersampling is useful because we want to get rid of the jigsaws resulting from low sample rate (pixel is always too low for continuous non-horizontal and non-vertical lines).</p>

<p>By sampling a pixel several times, we get the average color on that pixel. This will make that pixel not that “absolute”. Instead of either having the point or having no point, we can achieve a “having part of the point” effect. For example, if the point is black and the background is white, without supersampling, the pixel is either pure black or pure white, but supersampling may make it gray. From the macro view, lines may no longer be disconnected, and margins are more soft.</p>
<p>Our implementation is based primarily on the task 1’s, but instead of from <b>floor(min(x0, x1, x2)) + 0.5</b>, we do <b>floor(min(x0, x1, x2)) + (1 / sqrt(sample_rate)) / 2</b>, and the same for y. For instance, the sample_rate is 4, and we split the pixel into 4 subpixels, we are now at the bottom left subpixel’s center! Then we do another two for loops inside these big for loops, to go through the centers of the subpixels, and test if the subpixel is in the triangle. If so, we put the color inside the special sample_buffer. Our sample_buffer is managed so that, if the sample_rate is 4, the four subpixels of the bottom left pixel, takes the first 4 indices in the order from left to right, and then from bottom to up. Then the same order for the pixels. At the end, the resolve_to_framebuffer method will unpack the pixel into subpixels, and then take the average of them as the color for this pixel.</p>


<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task2-1.png" align="middle" width="400px"/>
        <figcaption align="middle">Supersamlping Rate 1</figcaption>
      </td>
      <td>
        <img src="images/task2-2.png" align="middle" width="400px"/>
        <figcaption align="middle">Supersamlping Rate 4</figcaption>
      </td>
      <td>
        <img src="images/task2-3.png" align="middle" width="400px"/>
        <figcaption align="middle">Supersamlping Rate 16</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>In lower supersampling rate, the tip of this triangle is too skinny for a pixel, so that the in-triangle test may simply fail. But higher supersampling rate allows testing more points in more equally distributed points in the pixel, and found that not all the points are outside of the triangle. Then it becomes a shallow pink. From the macro view, the triangle is now connected at 16 sample_rate, in contrast to the disconnected parts at 1 sample_rate.</p>


<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task2-1.png" align="middle" width="400px"/>
        <figcaption align="middle">Grid-based Supersamlping Rate 1</figcaption>
      </td>
      <td>
        <img src="images/task2-4.png" align="middle" width="400px"/>
        <figcaption align="middle">Jittered Supersamlping Rate 1</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>We implemented jittered sampling, which instead of sampling at the subpixel’s center—-what we did in grid-based sampling—-we sample at a random point in the subpixels. This achieves a result that the margins are more “coarse”, and is not that smooth compared to the grid-based result.</p>
<h2 align="middle">Part 3: Transforms</h2>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task3-1.png" align="middle" width="400px"/>
        <figcaption align="middle">"Soccer" Game</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>Here is our version of modified robot.svg, who is playing a soccer game, but the soccer ball is his/her head.</p>
<p>The left (from the screen’s point of view) arm is just a counterclockwise rotation of 80 degrees.</p>
<p>Then I made the left leg and right arm using similar techniques, which is rotation and then translate the lower arm/leg. The translation of lower arm/leg is to make it more natural, as if they were attached to the upper part. And the head was just a translation from the original location.</p>
<p>I could have changed the color of the robot, but that does not make it feel like these parts are on the same robot, and is just because of an aesthetic purpose.</p>

<h2 align="middle">Part 4: Barycentric coordinates</h2>
<p>Barycentric coordinates are used to describe the relative position of a point within a triangle. By using the math taught in lecture, we will be able to calculate alpha, beta, gamma, where their sum is 1. Alpha, beta, gamma’s proportion is also equal to the proportion of the distance from the sampling point to A, B, C.</p>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task4-1.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 7</figcaption>
      </td>
      <td>
        <img src="images/task4-2.png" align="middle" width="400px"/>
        <figcaption align="middle">Demostrating Triangle</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>By using this technique, we can calculate the weighted average of values from the three vertices. For example, we make a triangle with one pure R vertex, one pure G vertex, and one pure B vertex. The space between these points should include every possible RGB value combination, smoothly transitioning.</p>

<h2 align="middle">Part 5: "Pixel sampling" for texture mapping</h2>
<p>Our solution to task 5 is based on task 2’s solution. After we tested that a point is inside the triangle, we calculate the point’s relative position inside this triangle using the barycentric formula. The relative distance from this point to the three vertices will be the weights for the three vertices’ results of the texture, sicne we know the texture's triangle vertices.</p>
<p>Now the resulting <b>p_uv</b> is a Vertex2D with two points from 0 to 1. The nearest point sampling will round the two points to the nearest integrals. This will get the nearest texel in the texture.</p>
<p>The bilinear sampling is more complex. We basically will sample the 4 surrounding texels, then use lerp and other techniques taught in the lecture to weight the results from these 4 texels according to their distances to the sampling point.</p>


<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task5-1.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Sampling, Rate 1</figcaption>
      </td>
      <td>
        <img src="images/task5-2.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Sampling, Rate 16</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/task5-3.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear Sampling, Rate 1</figcaption>
      </td>
      <td>
        <img src="images/task5-4.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear Sampling, Rate 16</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>Both sampling techniques achieve smoother pixels at 16 sample_rate compared to their 1 sample_rate result. But the nearest sampling is too “sharp” at 1 sample_rate so that lines are seemingly disconnected. Bilinear sampling’s lines are way more smoother even at 1 sample_rate, as if supersampled. Even at 16 sample_rate, nearest sampling is still sharp compared to bilinear sampling, and shows more small jigsaws (though not very obvious since we supersampled).</p>
<p>When we have non-vertical and non-horizontal lines, or, more generally, when a point is smaller than a pixel can sample well, bilinear sampling will achieve better results since it is a weighted average of 4 surrounding pixels. Nearest sampling may simply ignore these texels, which may be useful, if they are not the nearest one.</p>
<h2 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h2>
<p>Because using only the full-resolution texture, which is what we did in task 5, we may get a picture with moiré or jigsaws resulting from a low sample rate. Low sample rate, or low screen resolution in the texture area does not require a too high texture resolution, so we just need to use a low resolution texture.</p>
<p>Our textures are saved in a mipmap format so that we can easily access different levels of resolution of the textures. When a texture subspace is mapped to a big screen subspace, we need to use a high resolution texture, and if mapped to a small screen subspace, we use low resolution to reduce sampling artifacts.</p>
<p>In our implementation, every pixel (or subpixel) (x, y) is calculated its required level of mipmap when we rasterize a triangle. By also computing (x + 1,y), (x, y + 1) pixels’ barycentric results, we can estimate d (u or v) / d (x or y), where u and v are the corresponding axis in the texture space.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task6-1.png" align="middle" width="1000px"/>
        <figcaption align="middle">Method to Get Mipmap Level</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>After calculating the level D, which is a floating point number, we can determine how to use the levels of mipmaps. Nearest level sampling will simply choose the closest ingeral to be the result. But bilinear level sampling will be the weighted average of the two neighboring levels (the lerp formula).</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task6-2.png" align="middle" width="400px"/>
        <figcaption align="middle">Level 0, Nearest Pixel</figcaption>
      </td>
      <td>
        <img src="images/task6-3.png" align="middle" width="400px"/>
        <figcaption align="middle">Level 0, Bilinear Pixel</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/task6-4.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Level, Nearest Pixel</figcaption>
      </td>
      <td>
        <img src="images/task6-5.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Level, Bilinear Pixel</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>Multiple samples per (screen) pixel, or supersampling, is the only one that requires significantly more memory, because every sample must be saved in an individual memory space in the sample buffer. Computation complexity grows linearly with the sample rate.</p>
<p>But bilinear pixel sampling requires constantly 3 more memory access (4 including the unavoidable access that is also in nearest pixel sampling), which is way cheaper than supersampling because 4 is a constant, and pixel sampling is at a lower level that supersampling must also include.</p>
<p>Level sampling techniques also include the calculation of level, and weighing the results from distinct levels, whose introduction leads to even longer computation time, and is slower than pixel sampling since it is at a higher level. Level sampling also requires 4/3 memory usage.</p>
<p>Choosing higher sample rate instead of lower, bilinear pixel sampling instead of nearest, bilinear level sampling instead of nearest or zero, can achieve better antialiasing effects.</p>
<p>In terms of the antialiasing power, supersampling is the most powerful, because sampling more pixels is like solving problems using brute force. We want to use pixel sampling and level sampling techniques to mimic the effects of supersampling, instead of replacing it.</p>
<p>Level sampling is the next effective, since it can greatly reduce artifacts resulting from far objects with high resolution texture.</p>
<p>Pixel sampling is the cheapest one, but can provide an effect similar to that of supersampling.</p>

</body>
</html>
